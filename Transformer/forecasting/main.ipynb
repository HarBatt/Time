{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9685b221",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeea6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from shared.component_logger import component_logger as logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a812411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3)\n",
    "np.random.seed(3)\n",
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63928878",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedd(nn.Module):\n",
    "    def __init__(self, in_dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696bdc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, n_heads=12, qkv_bias=True, attn_p=0., proj_p=0.):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim//n_heads\n",
    "        self.scale = self.head_dim** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim*3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_samples, n_tokens, dim = x.shape\n",
    "\n",
    "        # Sanity check\n",
    "        if dim != self.dim:\n",
    "            raise ValueError\n",
    "        \n",
    "        #(n_samples, seq_len + 1, 3 * dim)\n",
    "        qkv = self.qkv(x)  \n",
    "        \n",
    "        #(n_smaples, seq_len + 1, 3, n_heads, head_dim)\n",
    "        qkv = qkv.reshape(n_samples, n_tokens, 3, self.n_heads, self.head_dim)\n",
    "        \n",
    "        #(3, n_samples, n_heads, seq_len + 1, head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)  \n",
    "\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        #(n_samples, n_heads, head_dim, seq_len + 1)\n",
    "        k_t = k.transpose(-2, -1)  \n",
    "        \n",
    "        # (n_samples, n_heads, seq_len + 1, seq_len + 1)\n",
    "        dp = (q @ k_t)*self.scale \n",
    "        attn = dp.softmax(dim=-1)  # (n_samples, n_heads, seq_len + 1, seq_len + 1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        \n",
    "        # (n_samples, n_heads, seq_len +1, head_dim)\n",
    "        weighted_avg = attn @ v  \n",
    "        \n",
    "        # (n_samples, seq_len + 1, n_heads, head_dim)\n",
    "        weighted_avg = weighted_avg.transpose(1, 2)  \n",
    "        \n",
    "        # (n_samples, seq_len + 1, dim)\n",
    "        weighted_avg = weighted_avg.flatten(2)  \n",
    "        \n",
    "        # (n_samples, seq_len + 1, dim)\n",
    "        x = self.proj(weighted_avg)  \n",
    "        \n",
    "        # (n_samples, seq_len + 1, dim)\n",
    "        x = self.proj_drop(x)  \n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd7090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, p=0.):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x) # (n_samples, seq_len + 1, hidden_features)\n",
    "        x = self.act(x)  # (n_samples, seq_len + 1, hidden_features)\n",
    "        x = self.drop(x)  # (n_samples, seq_len + 1, hidden_features)\n",
    "        x = self.fc2(x)  # (n_samples, seq_len + 1, out_features)\n",
    "        x = self.drop(x)  # (n_samples, seq_len + 1, out_features)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e21b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, n_heads, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.attn = Attention(dim, n_heads=n_heads, qkv_bias=qkv_bias, attn_p=attn_p, proj_p=p)\n",
    "        self.norm2 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        hidden_features = int(dim * mlp_ratio)\n",
    "        self.mlp = MLP(in_features=dim, hidden_features=hidden_features, out_features=dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_norm = self.norm1(x)\n",
    "        out_attn = self.attn(out_norm)\n",
    "        x = x + out_attn\n",
    "\n",
    "        out_norm = self.norm2(x)\n",
    "        out_mlp = self.mlp(out_norm)\n",
    "        x = x + out_mlp\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ca9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeTransformer(nn.Module):\n",
    "    def __init__(self, in_dim, seq_len, embed_dim, out_dim, depth=12, n_heads=12, mlp_ratio=4., qkv_bias=True, p=0., attn_p=0.,):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedd(in_dim, embed_dim)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "\n",
    "        # Total number of tokens = 1 + seq_len\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, 1 + seq_len, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=p)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim,\n",
    "                n_heads=n_heads,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                p=p,\n",
    "                attn_p=attn_p,\n",
    "            )\n",
    "            for _ in range(depth)\n",
    "            ])\n",
    "\n",
    "        self.norm = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.head = nn.Linear(embed_dim, 28)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_samples = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_token = self.cls_token.expand(n_samples, -1, -1)  # (n_samples, 1, embed_dim)\n",
    "        x = torch.cat((cls_token, x), dim=1)  # (n_samples, 1 + seq_len, embed_dim)\n",
    "\n",
    "        # Added positional embedding of the cls token + all the patches to indicate the positions. \n",
    "        x = x + self.pos_embed  # (n_samples, 1 + seq_len, embed_dim)\n",
    "        x = self.pos_drop(x) # (n_samples, 1 + seq_len, embed_dim) (probability of dropping)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        cls_token_final = x[:, 0]  # just the CLS token\n",
    "        x = self.head(cls_token_final)\n",
    "\n",
    "        return x, cls_token_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28bd958",
   "metadata": {},
   "source": [
    "### Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4778c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDataset(Dataset):\n",
    "    def __init__(self, csv_file, seq_len):\n",
    "        self.file = csv_file\n",
    "        self.data = self.file.values\n",
    "        ori_data = self.data[::-1]\n",
    "        # Normalize the data\n",
    "        ori_data, (minimum, maximum) = self.MinMaxScaler(ori_data)\n",
    "        temp_data = [] \n",
    "        # Cut data by sequence length\n",
    "        for i in range(seq_len + 1, len(ori_data)):\n",
    "            x = ori_data[i-seq_len:i]\n",
    "            y = ori_data[i].reshape(1, -1)\n",
    "            temp_data.append((x, y))\n",
    "        self.temp_array = temp_data\n",
    "    \n",
    "    def MinMaxScaler(self, data):\n",
    "        minimum, maximum = np.min(data, 0), np.max(data, 0)\n",
    "        numerator = data - minimum\n",
    "        denominator = maximum - minimum\n",
    "        norm_data = numerator / (denominator + 1e-7)\n",
    "        return norm_data, (minimum, maximum)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.temp_array)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.Tensor(self.temp_array[index][0])\n",
    "        y = torch.Tensor(self.temp_array[index][1])\n",
    "        return (x, y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c08066",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"energy\"\n",
    "absolute_path = \"data/\" + data + \"_data.csv\" \n",
    "model_path = \"saved_model/\" + data + \"_time_transformer.pt\"\n",
    "df = pd.read_csv(absolute_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae40f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 1\n",
    "seq_len = 24\n",
    "batch_size = 64\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print_every = 100 # 2000 minibatches\n",
    "epochs = 50\n",
    "split = 0.7\n",
    "train_df = df[:int(len(df)*(split))]\n",
    "valid_df = df[int(len(df)*(split)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "868ecbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = TimeDataset(train_df, seq_len)\n",
    "validdataset = TimeDataset(valid_df, seq_len)\n",
    "trainloader = DataLoader(dataset=traindataset, batch_size=batch_size, shuffle=True)\n",
    "validloader = DataLoader(dataset=validdataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f462fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config = {\n",
    "        \"in_dim\": 28,\n",
    "        \"seq_len\": seq_len,\n",
    "        \"embed_dim\": 16,\n",
    "        \"depth\": 24,\n",
    "        \"n_heads\": 16,\n",
    "        \"qkv_bias\": True,\n",
    "        \"mlp_ratio\": 4,\n",
    "        \"out_dim\": 28\n",
    "}\n",
    "net = TimeTransformer(**custom_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f96da12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:52:26.669192: INFO: time: <cell line: 5>: Number of trainable parameters: 80108\n"
     ]
    }
   ],
   "source": [
    "def get_parameters_count(module):\n",
    "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "logger.log(\"Number of trainable parameters: {}\".format(get_parameters_count(net)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5102b3",
   "metadata": {},
   "source": [
    "### Define a Loss function and optimizer\n",
    "\n",
    "Let’s use a MSE loss and Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ae3ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f70f13",
   "metadata": {},
   "source": [
    "### Train the network\n",
    "\n",
    "This is when things start to get interesting. We simply have to loop over our data iterator, and feed the inputs to the network and optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f9a8041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-22 20:52:45.070716: INFO: time: <cell line: 1>: Epoch: 1; mse_train: 0.19434; mse_valid: 0.08987\n",
      "2022-07-22 20:53:02.101305: INFO: time: <cell line: 1>: Epoch: 2; mse_train: 0.05561; mse_valid: 0.04477\n",
      "2022-07-22 20:53:19.142146: INFO: time: <cell line: 1>: Epoch: 3; mse_train: 0.02918; mse_valid: 0.03545\n",
      "2022-07-22 20:53:36.277613: INFO: time: <cell line: 1>: Epoch: 4; mse_train: 0.02279; mse_valid: 0.03475\n",
      "2022-07-22 20:53:53.284123: INFO: time: <cell line: 1>: Epoch: 5; mse_train: 0.02057; mse_valid: 0.03323\n",
      "2022-07-22 20:54:10.435806: INFO: time: <cell line: 1>: Epoch: 6; mse_train: 0.01916; mse_valid: 0.03191\n",
      "2022-07-22 20:54:27.381480: INFO: time: <cell line: 1>: Epoch: 7; mse_train: 0.01806; mse_valid: 0.03098\n",
      "2022-07-22 20:54:46.001963: INFO: time: <cell line: 1>: Epoch: 8; mse_train: 0.01716; mse_valid: 0.03002\n",
      "2022-07-22 20:55:04.127743: INFO: time: <cell line: 1>: Epoch: 9; mse_train: 0.01646; mse_valid: 0.02898\n",
      "2022-07-22 20:55:22.284944: INFO: time: <cell line: 1>: Epoch: 10; mse_train: 0.01589; mse_valid: 0.02787\n",
      "2022-07-22 20:55:40.191509: INFO: time: <cell line: 1>: Epoch: 11; mse_train: 0.01545; mse_valid: 0.02794\n",
      "2022-07-22 20:55:58.797895: INFO: time: <cell line: 1>: Epoch: 12; mse_train: 0.01509; mse_valid: 0.02729\n",
      "2022-07-22 20:56:16.804002: INFO: time: <cell line: 1>: Epoch: 13; mse_train: 0.01482; mse_valid: 0.02642\n",
      "2022-07-22 20:56:34.851335: INFO: time: <cell line: 1>: Epoch: 14; mse_train: 0.01449; mse_valid: 0.02586\n",
      "2022-07-22 20:56:52.660372: INFO: time: <cell line: 1>: Epoch: 15; mse_train: 0.0142; mse_valid: 0.0253\n",
      "2022-07-22 20:57:10.510950: INFO: time: <cell line: 1>: Epoch: 16; mse_train: 0.01389; mse_valid: 0.02498\n",
      "2022-07-22 20:57:27.992528: INFO: time: <cell line: 1>: Epoch: 17; mse_train: 0.01359; mse_valid: 0.02373\n",
      "2022-07-22 20:57:46.047158: INFO: time: <cell line: 1>: Epoch: 18; mse_train: 0.0133; mse_valid: 0.02333\n",
      "2022-07-22 20:58:04.079605: INFO: time: <cell line: 1>: Epoch: 19; mse_train: 0.01295; mse_valid: 0.02212\n",
      "2022-07-22 20:58:21.896428: INFO: time: <cell line: 1>: Epoch: 20; mse_train: 0.01259; mse_valid: 0.02195\n",
      "2022-07-22 20:58:39.633367: INFO: time: <cell line: 1>: Epoch: 21; mse_train: 0.01228; mse_valid: 0.02115\n",
      "2022-07-22 20:58:57.252420: INFO: time: <cell line: 1>: Epoch: 22; mse_train: 0.012; mse_valid: 0.02092\n",
      "2022-07-22 20:59:14.633551: INFO: time: <cell line: 1>: Epoch: 23; mse_train: 0.01174; mse_valid: 0.02039\n",
      "2022-07-22 20:59:33.438105: INFO: time: <cell line: 1>: Epoch: 24; mse_train: 0.01152; mse_valid: 0.01998\n",
      "2022-07-22 20:59:52.097808: INFO: time: <cell line: 1>: Epoch: 25; mse_train: 0.01132; mse_valid: 0.01935\n",
      "2022-07-22 21:00:10.486853: INFO: time: <cell line: 1>: Epoch: 26; mse_train: 0.01115; mse_valid: 0.01908\n",
      "2022-07-22 21:00:28.201270: INFO: time: <cell line: 1>: Epoch: 27; mse_train: 0.011; mse_valid: 0.01895\n",
      "2022-07-22 21:00:46.205400: INFO: time: <cell line: 1>: Epoch: 28; mse_train: 0.01085; mse_valid: 0.01872\n",
      "2022-07-22 21:01:05.437696: INFO: time: <cell line: 1>: Epoch: 29; mse_train: 0.01072; mse_valid: 0.01873\n",
      "2022-07-22 21:01:22.556151: INFO: time: <cell line: 1>: Epoch: 30; mse_train: 0.01062; mse_valid: 0.0182\n",
      "2022-07-22 21:01:40.615226: INFO: time: <cell line: 1>: Epoch: 31; mse_train: 0.01049; mse_valid: 0.01807\n",
      "2022-07-22 21:01:57.434333: INFO: time: <cell line: 1>: Epoch: 32; mse_train: 0.01041; mse_valid: 0.01794\n",
      "2022-07-22 21:02:14.443059: INFO: time: <cell line: 1>: Epoch: 33; mse_train: 0.0103; mse_valid: 0.01766\n",
      "2022-07-22 21:02:31.193961: INFO: time: <cell line: 1>: Epoch: 34; mse_train: 0.01021; mse_valid: 0.01766\n",
      "2022-07-22 21:02:48.194030: INFO: time: <cell line: 1>: Epoch: 35; mse_train: 0.01012; mse_valid: 0.01727\n",
      "2022-07-22 21:03:04.367507: INFO: time: <cell line: 1>: Epoch: 36; mse_train: 0.01005; mse_valid: 0.01709\n",
      "2022-07-22 21:03:20.390534: INFO: time: <cell line: 1>: Epoch: 37; mse_train: 0.00998; mse_valid: 0.01672\n",
      "2022-07-22 21:03:36.514462: INFO: time: <cell line: 1>: Epoch: 38; mse_train: 0.0099; mse_valid: 0.01684\n",
      "2022-07-22 21:03:52.532014: INFO: time: <cell line: 1>: Epoch: 39; mse_train: 0.00984; mse_valid: 0.01702\n",
      "2022-07-22 21:04:08.542819: INFO: time: <cell line: 1>: Epoch: 40; mse_train: 0.00978; mse_valid: 0.01673\n",
      "2022-07-22 21:04:24.563048: INFO: time: <cell line: 1>: Epoch: 41; mse_train: 0.00972; mse_valid: 0.01639\n",
      "2022-07-22 21:04:40.596463: INFO: time: <cell line: 1>: Epoch: 42; mse_train: 0.00966; mse_valid: 0.01652\n",
      "2022-07-22 21:04:56.782397: INFO: time: <cell line: 1>: Epoch: 43; mse_train: 0.00959; mse_valid: 0.01613\n",
      "2022-07-22 21:05:12.987426: INFO: time: <cell line: 1>: Epoch: 44; mse_train: 0.00956; mse_valid: 0.01639\n",
      "2022-07-22 21:05:29.143996: INFO: time: <cell line: 1>: Epoch: 45; mse_train: 0.00951; mse_valid: 0.01625\n",
      "2022-07-22 21:05:45.609737: INFO: time: <cell line: 1>: Epoch: 46; mse_train: 0.00945; mse_valid: 0.01638\n",
      "2022-07-22 21:06:03.020083: INFO: time: <cell line: 1>: Epoch: 47; mse_train: 0.00941; mse_valid: 0.01596\n",
      "2022-07-22 21:06:20.374561: INFO: time: <cell line: 1>: Epoch: 48; mse_train: 0.00938; mse_valid: 0.01601\n",
      "2022-07-22 21:06:37.469570: INFO: time: <cell line: 1>: Epoch: 49; mse_train: 0.00933; mse_valid: 0.01598\n",
      "2022-07-22 21:06:54.932553: INFO: time: <cell line: 1>: Epoch: 50; mse_train: 0.0093; mse_valid: 0.01631\n",
      "2022-07-22 21:06:54.937541: INFO: time: <cell line: 34>: Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = torch.squeeze(labels, dim = 1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, embeddings = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = torch.squeeze(labels, dim = 1)\n",
    "            outputs, embeddings = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    if epoch%checkpoint == 0:\n",
    "        torch.save({'epoch': epoch, 'model_state_dict': net.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(), 'train_loss': train_loss, \n",
    "                    'valid_loss': valid_loss}, model_path)\n",
    "        logger.log(\"Epoch: {}; mse_train: {}; mse_valid: {}\".format(epoch + 1, np.round(train_loss/len(trainloader), 5), np.round(valid_loss/len(validloader), 5)))\n",
    "\n",
    "logger.log('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
